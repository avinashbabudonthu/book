# Kafka producer properties
* Write below properties to connect Producer to kafka
```
import java.util.Properties;
import org.apache.kafka.clients.producer.ProducerConfig;

private Properties getProperties() {
        Properties properties = new Properties();
        // bootstrap.servers
        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:29092");
        // key.serializer
        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // value.serializer
        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());
        // properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());
		// check JsonSerializer class below
        
        properties.put(ProducerConfig.ACKS_CONFIG, "all");
        // properties.put(ProducerConfig.ACKS_CONFIG, "0");
        
        properties.put(ProducerConfig.RETRIES_CONFIG, "3");
        // The amount of time to wait before attempting to retry a failed request to a given topic partition.
        // This avoids repeatedly sending requests in a tight loop under some failure scenarios.
        // This value is the initial backoff value and will increase exponentially for each failed request,
        // up to the retry.backoff.max.ms value.
        // retry.backoff.ms
        properties.put(ProducerConfig.RETRY_BACKOFF_MS_CONFIG, 100);
        properties.put(ProducerConfig.RETRY_BACKOFF_MAX_MS_CONFIG, 10000);

        properties.put(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, 120000);

        // The producer groups together any records that arrive in between request transmissions into a single batched request.
        // Normally this occurs only under load when records arrive faster than they can be sent out.
        // However in some circumstances the client may want to reduce the number of requests even under moderate load
        properties.put(ProducerConfig.LINGER_MS_CONFIG, "1");
        // ensure we don't push duplicates
        properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);
        // properties.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, "false");
        
        // batch.size
        properties.put(ProducerConfig.BATCH_SIZE_CONFIG, "400");
        
        // partitioner.class
        properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, RoundRobinPartitioner.class.getName());
        // properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, DefaultPartitioner.class.getName()); // uses Sticky partition
        
       // properties.put(ProducerConfig.LINGER_MS_CONFIG, "20");
       // properties.put(ProducerConfig.BATCH_SIZE_CONFIG, Integer.toString(32 * 1024));

        // compression.type
        // The compression type for all data generated by the producer. The default is none (i.e. no compression).
        // Valid values are - none, gzip, snappy, lz4 , zstd
        // Compression is of full batches of data, so the efficacy of batching will also impact the compression ratio
        // (more batching means better compression)
       // properties.put(ProducerConfig.COMPRESSION_TYPE_CONFIG, "snappy");

        return properties;
    }
```
* JsonSerializer class
```
package com.kafka;

import com.fasterxml.jackson.core.JsonProcessingException;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.extern.slf4j.Slf4j;
import org.apache.kafka.common.serialization.Serializer;

@Slf4j
public class JsonSerializer implements Serializer<Object> {
    private static final ObjectMapper OBJECT_MAPPER = new ObjectMapper();

    @Override
    public byte[] serialize(String topic, Object data) {
        byte[] result = null;
        if(null != data) {
            try {
                String json = OBJECT_MAPPER.writeValueAsString(data);
                result = json.getBytes();
            } catch (JsonProcessingException e) {
                log.error("Exception converting object to JSON", e);
            }
        }
        return result;
    }
}

```